{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-synchikov/n_worker/blob/main/%D0%BD%D0%B5%D0%B9%D1%80%D0%BE_%D1%81%D0%BE%D1%82%D1%80%D1%83%D0%B4%D0%BD%D0%B8%D0%BA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0K2Oe6lJriu"
      },
      "source": [
        "–ù–µ–π—Ä–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç. –û–±—Ä–∞—Å—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è - –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—è. –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π - –ø—Ä–æ—Ñ–∏–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª –í–∏–∫–∏–ø–µ–¥–∏–∏, —Ä—É—Å—Å–∫–∏–π —Å–µ–≥–º–µ–Ω—Ç."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjl7nL5DBcWo"
      },
      "source": [
        "1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqa14lrNspce"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install llama_index pyvis Ipython langchain pypdf langchain_community\n",
        "!pip install llama-index-llms-huggingface\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-index-embeddings-langchain\n",
        "!pip install langchain-huggingface\n",
        "!pip install sentencepiece accelerate\n",
        "!pip install -U bitsandbytes\n",
        "!pip install peft\n",
        "!pip install llama-index-readers-wikipedia wikipedia\n",
        "!pip install openai tiktoken langchain langchain-openai langchain-community chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2EYJO0vsxDP"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core import KnowledgeGraphIndex\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core.graph_stores import SimpleGraphStore\n",
        "from llama_index.core import StorageContext\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
        "import torch\n",
        "import llama_index\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "from pyvis.network import Network\n",
        "from llama_index.core.llama_pack import download_llama_pack\n",
        "\n",
        "\n",
        "LlamaGuardModeratorPack = download_llama_pack(\n",
        "    \"LlamaGuardModeratorPack\", \"./llamaguard_pack\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYCG3JFlAJLy"
      },
      "outputs": [],
      "source": [
        "!pip install openai llama_index \"arize-phoenix[evals]\" gcsfs nest-asyncio \"openinference-instrumentation-llama-index>=2.0.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW2PvKclDb2j"
      },
      "source": [
        "–∑–∞–ø—É—Å–∫ Phoenix –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º LlamaIndex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIvfIuKKa105"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "import phoenix as px\n",
        "\n",
        "from phoenix.evals import (\n",
        "    HallucinationEvaluator,\n",
        "    OpenAIModel,\n",
        "    QAEvaluator,\n",
        "    RelevanceEvaluator,\n",
        "    run_evals,\n",
        ")\n",
        "from phoenix.session.evaluation import get_qa_with_reference, get_retrieved_documents\n",
        "from phoenix.trace import DocumentEvaluations, SpanEvaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gzDc0oYAdaY"
      },
      "outputs": [],
      "source": [
        "nest_asyncio.apply()  # –Ω–µ–æ–±—Ö–æ–¥–∏–º –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –≤ —Å—Ä–µ–¥–µ –Ω–æ—É—Ç–±—É–∫–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session = px.launch_app()"
      ],
      "metadata": {
        "id": "B2S6tPzDzT1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25R-QHtuAmjR"
      },
      "outputs": [],
      "source": [
        "\n",
        "from openinference.instrumentation.llama_index import LlamaIndexInstrumentor\n",
        "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
        "from opentelemetry.sdk.trace import TracerProvider\n",
        "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
        "session = px.launch_app()\n",
        "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
        "tracer_provider = TracerProvider()\n",
        "tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter(endpoint)))\n",
        "\n",
        "LlamaIndexInstrumentor().instrument(tracer_provider=tracer_provider)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD9ostsyeq2x"
      },
      "source": [
        "–ü—Ä–∏ –ø–æ—è–≤–ª–µ–Ω–∏–∏ –æ—à–∏–±–∫–∏  DependencyConflict: requested: \"llama-index-core >= 0.10.43\" but found: \"tenacity 9.0.0\" —Å–ª–µ–¥—É–µ—Ç –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ä–µ–¥—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∏ –∑–∞–Ω–æ–≤–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–¥."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLdPr4NFCHwE"
      },
      "source": [
        "–ø–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Huggin Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pWhmKU2t5Sj"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "HF_TOKEN=\"\"\n",
        "# –í—Å—Ç–∞–≤—å—Ç–µ –≤–∞—à —Ç–æ–∫–µ–Ω (–∑–¥–µ—Å—å —É–∫–∞–∑–∞–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω)\n",
        "login(HF_TOKEN, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkk2sJAMJS8N"
      },
      "source": [
        "–≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è –∫ –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XL1cOcOluKcY"
      },
      "outputs": [],
      "source": [
        "def messages_to_prompt(messages):\n",
        "    prompt = \"\"\n",
        "    for message in messages:\n",
        "        if message.role == 'system':\n",
        "            prompt += f\"<s>{message.role}\\n{message.content}</s>\\n\"\n",
        "        elif message.role == 'user':\n",
        "            prompt += f\"<s>{message.role}\\n{message.content}</s>\\n\"\n",
        "        elif message.role == 'bot':\n",
        "            prompt += f\"<s>bot\\n\"\n",
        "\n",
        "    # ensure we start with a system prompt, insert blank if needed\n",
        "    if not prompt.startswith(\"<s>system\\n\"):\n",
        "        prompt = \"<s>system\\n</s>\\n\" + prompt\n",
        "\n",
        "    # add final assistant prompt\n",
        "    prompt = prompt + \"<s>bot\\n\"\n",
        "    return prompt\n",
        "\n",
        "def completion_to_prompt(completion):\n",
        "    return f\"<s>system\\n</s>\\n<s>user\\n{completion}</s>\\n<s>bot\\n\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgYun4lvIChp"
      },
      "source": [
        "–ó–∞–≥—Ä—É–∂–∞–µ–º LMM –º–æ–¥–µ–ª—å saiga_mistral_7b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7wlvw1IuO7f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "\n",
        "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è, –∏–Ω–∞—á–µ –º–æ–¥–µ–ª—å –Ω–µ –≤—ã–ø–æ–ª–Ω–∏—Ç—å—Å—è –≤ –∫–æ–ª–∞–±–µ\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "# –ó–∞–¥–∞–µ–º –∏–º—è –º–æ–¥–µ–ª–∏\n",
        "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –º–µ—Ç–æ–¥—É PEFT (–≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ LoRA)\n",
        "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å, –µ–µ –∏–º—è –±–µ—Ä–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –¥–ª—è LoRA\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,          # –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏\n",
        "    quantization_config=quantization_config, # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è\n",
        "    torch_dtype=torch.float16,               # —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö\n",
        "    device_map=\"auto\"                        # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —Ç–∏–ø–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞\n",
        ")\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º LoRA –º–æ–¥–µ–ª—å\n",
        "model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞\n",
        "# –ú–æ–∂–Ω–æ –Ω–µ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å, –Ω–æ —è–≤–Ω–æ–µ –≤—Å–µ–≥–¥–∞ –ª—É—á—à–µ –Ω–µ—è–≤–Ω–æ–≥–æ\n",
        "model.eval()\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkCtFNKxINcc"
      },
      "source": [
        "–ó–∞–¥–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpR6KLPLw0yo"
      },
      "outputs": [],
      "source": [
        "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
        "print(generation_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghGSqKh3JLWa"
      },
      "source": [
        "–ø–µ—Ä–µ–¥–∞–µ–º –≤ –∫–ª–∞—Å—Å —Ä–∞–Ω–µ–µ –æ–±—ä—è–≤–ª–µ–Ω–Ω—ã–µ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULDWhNTKw5k8"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFaceLLM(\n",
        "    model=model,             # –º–æ–¥–µ–ª—å\n",
        "    model_name=MODEL_NAME,   # –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏\n",
        "    tokenizer=tokenizer,     # —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä\n",
        "    max_new_tokens=generation_config.max_new_tokens, # –ø–∞—Ä–∞–º–µ—Ç—Ä –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–¥–µ—Å—å, –∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ generate_kwargs, –∏–Ω–∞—á–µ –æ—à–∏–±–∫–∞ –¥–≤–æ–π–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
        "    model_kwargs={\"quantization_config\": quantization_config}, # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è\n",
        "    generate_kwargs = {   # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞\n",
        "      \"bos_token_id\": generation_config.bos_token_id, # —Ç–æ–∫–µ–Ω –Ω–∞—á–∞–ª–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
        "      \"eos_token_id\": generation_config.eos_token_id, # —Ç–æ–∫–µ–Ω –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
        "      \"pad_token_id\": generation_config.pad_token_id, # —Ç–æ–∫–µ–Ω –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—É–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –µ—â—ë –Ω–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∞)\n",
        "      \"no_repeat_ngram_size\": generation_config.no_repeat_ngram_size,\n",
        "      \"repetition_penalty\": generation_config.repetition_penalty,\n",
        "      \"temperature\": generation_config.temperature,\n",
        "      \"do_sample\": True,\n",
        "      \"top_k\": 50,\n",
        "      \"top_p\": 0.95\n",
        "    },\n",
        "    messages_to_prompt=messages_to_prompt,     # —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –∫ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–º—É —Ñ–æ—Ä–º–∞—Ç—É\n",
        "    completion_to_prompt=completion_to_prompt, # —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n",
        "    device_map=\"auto\",                         # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_vX0wZ6IWlV"
      },
      "source": [
        "–∑–∞–≥—Ä—É–∂–∞–µ–º —Ä–∏–¥–µ—Ä –¥–ª—è –í–∏–∫–∏–ø–µ–¥–∏–∏ –∏ —É–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π —Ä–∞–∑–¥–µ–ª, –≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ —ç—Ç–æ —Ä–∞–∑–¥–µ–ª –ê—Å—Ç—Ä–æ–Ω–æ–º–∏–∏ ru-—Å–µ–≥–º–µ–Ω—Ç–∞ –í–∏–∫–∏–ø–µ–¥–∏–∏."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeQqaOmDw_ZO"
      },
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ –≤–∏–∫–∏–ø–µ–¥–∏–∏\n",
        "from llama_index.readers.wikipedia import WikipediaReader\n",
        "\n",
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–∞ WikipediaReader\n",
        "reader = WikipediaReader()\n",
        "\n",
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤–∏–∫–∏–ø–µ–¥–∏–∏\n",
        "docs = reader.load_data(\n",
        "    pages=[\"–ê—Å—Ç—Ä–æ–Ω–æ–º–∏—è\"],  # –∑–∞–ø—Ä–æ—Å —Ä–∞–∑–¥–µ–ª–∞ –Ω–∞ —Ç–µ–º—É –ò–ò\n",
        "    lang_prefix = 'ru'                  # –∏–∑ —Ä—É—Å–∫–æ–∑—ã—á–Ω–æ–π –∑–æ–Ω—ã –≤–∏–∫–∏–ø–µ–¥–∏–∏\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQdSMpx6JJQQ"
      },
      "source": [
        "–û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å –≤–Ω–µ–¥—Ä–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cph1GAalxE5E"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface  import HuggingFaceEmbeddings\n",
        "embed_model = LangchainEmbedding(\n",
        "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGe6NM-hKORw"
      },
      "source": [
        "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è LlamaIndex:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lIQm45D0xhE"
      },
      "outputs": [],
      "source": [
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ ServiceContext (–≥–ª–æ–±–∞–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ LLM)\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "Settings.chunk_size = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--oD0o5j04bQ"
      },
      "outputs": [],
      "source": [
        "# –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ –≥—Ä–∞—Ñ–æ–≤–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ\n",
        "graph_store = SimpleGraphStore()\n",
        "\n",
        "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –≤ StorageContext\n",
        "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us6JqTOkKWIe"
      },
      "source": [
        "—Å–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OblE820pyuFH"
      },
      "outputs": [],
      "source": [
        "indexKG = KnowledgeGraphIndex.from_documents( documents=docs,               # –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–æ–≤\n",
        "                           max_triplets_per_chunk=3,        # —Å–∫–æ–ª—å–∫–æ –æ–±—Ä–∞–±–æ—Ç—ã–≤–∞—Ç—å —Ç—Ä–∏–ø–ª–µ—Ç–æ–≤ —Å–≤—è–∑–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
        "                           show_progress=True,              # –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è\n",
        "                           include_embeddings=True,         # –≤–∫–ª—é—á–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –≤–ª–æ–∂–µ–Ω–∏–π –≤ –∏–Ω–¥–µ–∫—Å –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏\n",
        "                           storage_context=storage_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTenW2GUKhAf"
      },
      "source": [
        "–≤–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvY6Qugi-qCq"
      },
      "outputs": [],
      "source": [
        "query = \"–†–∞—Å—Å–∫–∞–∂–∏ –æ –Æ–ø–∏—Ç–µ—Ä–µ\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7feecfEK0Sz"
      },
      "source": [
        "—Ñ–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏, –ø—Ä–æ–ø–∏—Å—ã–≤–∞–µ–º –≤ –Ω–µ–µ –ø—Ä–æ–º—Ç\n",
        "–ø–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArcnN-HV9Hvq"
      },
      "outputs": [],
      "source": [
        "query = query\n",
        "query_engine = indexKG.as_query_engine(include_text=True, verbose=True)\n",
        "#\n",
        "message_template =f\"\"\"<s>system\n",
        "–ù–∞–ø–∏—à–∏ –Ω–µ–±–æ–ª—å—à–æ–π —Ä–∞—Å—Å–∫–∞–∑ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ò—Å—Ç–æ—á–Ω–∏–∫–æ–º. –ü—Ä–æ–≤–µ—Ä—å, –µ—Å—Ç—å –ª–∏ –≤ –ò—Å—Ç–æ—á–Ω–∏–∫–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞—Ö –í–æ–ø—Ä–æ—Å–∞.\n",
        "–ï—Å–ª–∏ –Ω–µ—Ç, —Ç–æ –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏: '—è –Ω–µ –∑–Ω–∞—é'. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π!</s>\n",
        "<s>user\n",
        "–í–æ–ø—Ä–æ—Å: {query}\n",
        "–ò—Å—Ç–æ—á–Ω–∏–∫:\n",
        "</s>\n",
        "\"\"\"\n",
        "#\n",
        "response = query_engine.query(message_template)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTgcF-UNA9VY"
      },
      "source": [
        "–û—Ç–≤–µ—Ç –Ω–µ —Å–æ–≤—Å–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø—Ä–æ–º—Ç—É, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤—ã–¥–∞–Ω–∞ —Ç–µ–∑–∏—Å–Ω–æ, —á—Ç–æ –Ω–µ –ø–æ—Ö–æ–∂–µ –Ω–∞ —Ä–∞—Å—Å–∫–∞–∑, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–ø—Ä–æ—à–µ–Ω –≤ –ø—Ä–æ–º—Ç–µ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZz-71ug9_rY"
      },
      "outputs": [],
      "source": [
        "print(f\"üöÄ –û—Ç–∫—Ä–æ–π Phoenix UI –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ç—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∏ –ø–æ —Å—Å—ã–ª–∫–µ: {session.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1Y7AjnOLNVD"
      },
      "source": [
        "—É–ª—É—á—à–∏–º –≤—ã–≤–æ–¥ –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π HyDE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGBniGZC9blA"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.indices.query.query_transform import HyDEQueryTransform # –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
        "from llama_index.core.query_engine import TransformQueryEngine # –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥ –º–µ—Ç–æ–¥ –¥–≤–∏–∂–æ–∫ –∑–∞–ø—Ä–æ—Å–æ–≤\n",
        "from IPython.display import Markdown, display # –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –∫–∞–∫ markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-beQy7sS9qdo"
      },
      "outputs": [],
      "source": [
        "hyde = HyDEQueryTransform(include_original=True)\n",
        "hyde_query_engine = TransformQueryEngine(query_engine, hyde)\n",
        "response = hyde_query_engine.query(query)\n",
        "display(Markdown(f\"<b>{response}</b>\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3xpP_xIBFmo"
      },
      "source": [
        "—Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–æ–ª–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–ø—Ä–æ—Å—É –∏ –ø—Ä–æ–º—Ç—É"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpyzvUNQLr1-"
      },
      "source": [
        "–ó–∞—â–∏—Ç–∞ –≤–≤–æ–¥–∞\\–≤—ã–≤–æ–¥–∞. –î–ª—è —Ä–∞–±–æ—Ç—ã –¥–∞–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–±—ä–µ–º –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏ –±–æ–ª—å—à–µ —á–µ–º –¥–æ–µ—Ç –±–µ—Å–ø–ª–∞—Ç–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ (<15Gb)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwa-McrsLwQ8"
      },
      "source": [
        "–ó–∞–≥—Ä—É–∂–∞–µ–º LlamaGuard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Da_eNspu9osX"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ra5EOr99VKx"
      },
      "outputs": [],
      "source": [
        "# download and install dependencies\n",
        "LlamaGuardModeratorPack = download_llama_pack(\n",
        "    \"llamaguard-7b.Q3_K_S.gguf\", \"./llamaguard_pack\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibEYde7yUqs3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACE_ACCESS_TOKEN\"] = \"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\"\n",
        "llamaguard_pack = LlamaGuardModeratorPack()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcWs_Z04L-XS"
      },
      "source": [
        "—Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∑–∞—â–∏—â–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65GtkMeZWtQB"
      },
      "outputs": [],
      "source": [
        "def questions(query):\n",
        "  query = query\n",
        "  query_engine = indexKG.as_query_engine(include_text=True, verbose=True)\n",
        "  #\n",
        "  message_template =f\"\"\"<s>system\n",
        "  –ù–∞–ø–∏—à–∏ –Ω–µ–±–æ–ª—å—à–æ–π —Ä–∞—Å—Å–∫–∞–∑ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ò—Å—Ç–æ—á–Ω–∏–∫–æ–º. –ü—Ä–æ–≤–µ—Ä—å, –µ—Å—Ç—å –ª–∏ –≤ –ò—Å—Ç–æ—á–Ω–∏–∫–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞—Ö –í–æ–ø—Ä–æ—Å–∞.\n",
        "  –ï—Å–ª–∏ –Ω–µ—Ç, —Ç–æ –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏: '—è –Ω–µ –∑–Ω–∞—é'. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π!</s>\n",
        "  <s>user\n",
        "  –í–æ–ø—Ä–æ—Å: {query}\n",
        "  –ò—Å—Ç–æ—á–Ω–∏–∫:\n",
        "  </s>\n",
        "  \"\"\"\n",
        "  #\n",
        "  response = query_engine.query(message_template)\n",
        "  return (response.response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPTypqfd9_4g"
      },
      "outputs": [],
      "source": [
        "def moderate_and_query(query):\n",
        "    # Moderate the user input\n",
        "    moderator_response_for_input = llamaguard_pack.run(query)\n",
        "    print(f\"moderator response for input: {moderator_response_for_input}\")\n",
        "\n",
        "    # Check if the moderator response for input is safe\n",
        "    if moderator_response_for_input == \"safe\":\n",
        "        response = questions(query)\n",
        "\n",
        "        # Moderate the LLM output\n",
        "        moderator_response_for_output = llamaguard_pack.run(str(response))\n",
        "        print(\n",
        "            f\"moderator response for output: {moderator_response_for_output}\"\n",
        "        )\n",
        "\n",
        "        # Check if the moderator response for output is safe\n",
        "        if moderator_response_for_output != \"safe\":\n",
        "            response = (\n",
        "                \"The response is not safe. Please ask a different question.\"\n",
        "            )\n",
        "    else:\n",
        "        response = \"This query is not safe. Please ask a different question.\"\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpmFpODcN9GW"
      },
      "source": [
        "–∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É –∑–∞—â–∏—Ç—ã"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wsr9em7-_-p"
      },
      "outputs": [],
      "source": [
        "resp = moderate_and_query(query)\n",
        "print (resp)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}